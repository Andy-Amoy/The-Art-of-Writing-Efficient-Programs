In this chapter, we have learned about the computing capabilities of the main processor and how to use them effectively. The key to high performance is to make maximum use of all available computing resources: a program that computes two results at the same time is faster than the one that computes the second result later (assuming the computing power is available). As we have learned, the CPU has a lot of computing units for various types of computations, most of which are idle at any given moment unless the program is very highly optimized.

We have seen that the main restriction on efficient use of the CPU's instruction-level parallelism is usually the data dependencies: there simply isn't enough work that can be done in parallel to keep the CPU busy. The hardware solution to this problem is pipelining: the CPU doesn't just execute the code at the current point in the program but takes some computations from the future that have no unsatisfied data dependencies and executes them in parallel. This works well as long as the future is well known: the CPU cannot execute the computations from the future if it cannot determine what these computations are. Whenever the CPU must wait to determine what machine instructions are to be executed next, the pipeline stalls. To reduce the frequency of such stalls, the CPU has special hardware that predicts the most probable future, the path through the conditional code that is likely to be taken, and executes that code speculatively. The performance of the program, thus, depends critically on how well this prediction works.

We have learned the use of special tools that can help measure the efficiency of the code and identify the bottlenecks that limit the performance. Guided by the measurements, we have studied several optimization techniques that can make the program utilize more of the CPU resources, wait less and compute more, and, in the end, help to improve performance.

Throughout this chapter, we have persistently ignored one step every computation must do eventually: access the memory. The inputs for any expression reside in memory and must be brought into the registers before the rest of the computation takes place. The intermediate results can be stored in the registers, but eventually, something has to be written back into memory, or the entire code has no lasting effect. As it turns out, memory operations (reads and writes) have a significant effect on performance and, in many programs, are the limiting factor that prevents further optimizations. The next chapter is dedicated to studying the CPU-memory interactions.







