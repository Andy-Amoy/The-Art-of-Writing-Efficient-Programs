
收集关于程序性能信息的最简单的方法是运行，并测量运行所花费的时间。当然，要进行有效的优化，我们需要更多的数据：最好知道程序的哪些部分耗时最长，这样我们就不会浪费自己的时间来优化代码，这些代码可能非常低效，但也只需要很少的时间，因此不会对最终结果有任何贡献。

我们在示例程序中添加计时器时，已经看到了一个简单的例子：现在我们知道排序本身需要多长时间。简而言之，这就是基准测试的全部。其余的工作都是体力活，用计时器检测代码，收集信息，并以可读的格式进行报告。看看有什么工具可以实现这一点，先从语言本身提供的计时器开始。

\subsubsubsection{2.3.1\hspace{0.2cm}C++的chrono计时器}

C++在它的chrono库中有一些工具可以用来收集计时信息。可以测量程序中通过任意两点之间所需的时间:

%\hspace*{\fill} \\ %插入空行
\noindent
\textbf{example.C}
\begin{lstlisting}[style=styleCXX]
#include <chrono>
using std::chrono::duration_cast;
using std::chrono::milliseconds;
using std::chrono::system_clock;
  …
auto t0 = system_clock::now();
  … do some work …
auto t1 = system_clock::now();
auto delta_t = duration_cast<milliseconds>(t1 – t0);
cout << "Time: " << delta_t.count() << endl;
\end{lstlisting}

应该指出的是，C++计时时钟测量的是实时时间(通常称为挂钟时间)。通常，这就是想要测量的时间。更详细的分析通常需要测量CPU时间，即CPU的工作时，以及在CPU空闲时的时间。单线程程序中，CPU时间不能大于实际时间，当程序是计算密集型时，这两个时间理论上相同，这意味着完全使用CPU进行计算了。另一方面，用户界面程序会把大部分时间都花在等待用户和闲置CPU上，所以我们希望CPU时间尽可能的短：这样的程序是高效的，并且使用尽可能少的CPU资源来满足用户的请求。因此，我们必须超越C++17。


\subsubsubsection{2.3.2\hspace{0.2cm}高精度计时器}

为了测试CPU时间，我们必须使用特定于操作系统的系统函数，在Linux和其他posix兼容的系统上，可以使用\texttt{clock\_gettime()}来使用硬件的高精度计时器:

%\hspace*{\fill} \\ %插入空行
\noindent
\textbf{clocks.C}
\begin{lstlisting}[style=styleCXX]
timespec t0, t1;
clockid_t clock_id = …; // Specific clock
clock_gettime(clock_id, &t0);
  … do some work …
clock_gettime(clock_id, &t1);
double delta_t = t1.tv_sec – t0.tv_sec +
  1e-9*(t1.tv_nsec – t0.tv_nsec);
\end{lstlisting}

第二个参数的函数返回当前时间，\texttt{tv\_sec}是过去某一时刻到现在的秒数，\texttt{tv\_nsec}是上一整个秒到现在的纳秒数。时间的起源并不重要，因为我们总是测量时间间隔。这里要先减去秒，然后再加纳秒。

我们可以在前面的代码中使用的几个硬件计时器，其中一个由\texttt{clock\_id}变量的值选择，这些计时器中的计时器与我们已经使用过的系统或实时时钟相同。ID为\texttt{CLOCK\_REALTIME}。我们感兴趣的另外两个计时器是两个CPU计时器:\texttt{CLOCK\_PROCESS\_CPUTIME\_ID}是测量当前程序使用的CPU时间的计时器，而\texttt{CLOCK\_THREAD\_CPUTIME\_ID}是测量调用线程使用的时间的计时器。

对代码进行基准测试时，从多个计时器的测量结果通常是很有帮助的。一个单线程程序不间断进行计算时，三个计时器应该返回相同的结果:

%\hspace*{\fill} \\ %插入空行
\noindent
\textbf{clocks.C}
\begin{lstlisting}[style=styleCXX]
double duration(timespec a, timespec b) {
	return a.tv_sec - b.tv_sec + 1e-9*(a.tv_nsec - b.tv_nsec);
}
…
{
	timespec rt0, ct0, tt0;
	clock_gettime(CLOCK_REALTIME, &rt0);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct0);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt0);
	constexpr double X = 1e6;
	double s = 0;
	for (double x = 0; x < X; x += 0.1) s += sin(x);
	timespec rt1, ct1, tt1;
	clock_gettime(CLOCK_REALTIME, &rt1);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct1);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt1);
	cout << "Real time: " << duration(rt1, rt0) << "s, "
	  "CPU time: " << duration(ct1, ct0) << "s, "
	  "Thread time: " << duration(tt1, tt0) << "s" <<
	  endl;
}
\end{lstlisting}

这里的“CPU密集型的工作”是一种计算，所以三个计时器的时间几乎相同。可以用一种计算的方法观察到这一点。时间将取决于计算机的运行速度，结果是这样的:

\begin{tcblisting}{commandshell={}}
Real time: 0.3717s, CPU time: 0.3716s, Thread time: 0.3716s
\end{tcblisting}

如果CPU时间与实际时间不匹配，则很可能是机器过载(许多其他进程正在争夺CPU资源)，或程序耗尽内存(如果程序使用的内存超过机器上的物理内存，它将不得不使用慢得多的磁盘交换，当程序等待从磁盘调入内存时，CPU无法执行任何工作)。

另一方面，如果没有太多的计算，而是等待用户输入，或者从网络接收数据，亦或做一些其他不占用太多CPU资源的工作，我们将看到不同的结果。观察这种行为的最简单方法是调用\texttt{sleep()}函数:

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{clocks.C}
\begin{lstlisting}[style=styleCXX]
{
	timespec rt0, ct0, tt0;
	clock_gettime(CLOCK_REALTIME, &rt0);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct0);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt0);
	sleep(1);
	timespec rt1, ct1, tt1;
	clock_gettime(CLOCK_REALTIME, &rt1);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct1);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt1);
	cout << "Real time: " << duration(rt1, rt0) << "s, "
	  "CPU time: " << duration(ct1, ct0) << "s, "
	  "Thread time: " << duration(tt1, tt0) << "s" <<
  	  endl;
}
\end{lstlisting}

可以看到休眠程序几乎不怎么使用CPU:

\begin{tcblisting}{commandshell={}}
Real time: 1.000s, CPU time: 3.23e-05s, Thread time: 3.32e-05s
\end{tcblisting}

对于传输套接字或读取文件阻塞的程序，或者正在等待用户操作的程序，也是这样几乎不怎么使用CPU。

目前为止，还没有看到两个CPU计时器之间的任何区别(除非程序使用线程，否则您不会看到任何区别)。我们可以让这个需要大量计算的程序完成同样的工作，但为其开辟一个单独的线程进行计算:

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{clocks.C}
\begin{lstlisting}[style=styleCXX]
{
	timespec rt0, ct0, tt0;
	clock_gettime(CLOCK_REALTIME, &rt0);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct0);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt0);
	constexpr double X = 1e6;
	double s = 0;
	auto f = std::async(std::launch::async,
	  [&]{ for (double x = 0; x < X; x += 0.1) s += sin(x);
	  });
	f.wait();
	timespec rt1, ct1, tt1;
	clock_gettime(CLOCK_REALTIME, &rt1);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct1);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt1);
	cout << "Real time: " << duration(rt1, rt0) << "s, "
	  "CPU time: " << duration(ct1, ct0) << "s, "
	  "Thread time: " << duration(tt1, tt0) << "s" <<
	  endl;
}
\end{lstlisting}

总的计算量保持不变，并且还是只有一个线程在执行这项工作，因此我们不期望对实时性或整个进程的CPU时间有任何改进。不过，调用计时器的线程现在是空闲的，它所做的就是等待\texttt{std::async}返回\texttt{future}，直到工作完成。这种等待与前面例子中的\texttt{sleep()}非常类似:

\begin{tcblisting}{commandshell={}}
Real time: 0.3774s, CPU time: 0.377s, Thread time: 7.77e-05s
\end{tcblisting}

现在，实时和进程的CPU时间与“繁重计算”示例中的CPU时间相似，但线程特定的CPU时间较低，就像“休眠”示例中的CPU时间一样。因为程序都在做大量的计算，但是使用计时器的线程，大部分时间都在休眠。

大多数情况下，如果打算使用线程进行计算，我们的目标是更快地进行更多的计算，因此会使用几个线程，并将不同的工作分配给它们。我们修改一下前面的例子，让其也在主线程上能进行计算:

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{clocks.C}
\begin{lstlisting}[style=styleCXX]
{
	timespec rt0, ct0, tt0;
	clock_gettime(CLOCK_REALTIME, &rt0);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct0);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt0);
	constexpr double X = 1e6;
	double s1 = 0, s2 = 0;
	auto f = std::async(std::launch::async,
	  [&]{ for (double x = 0; x < X; x += 0.1) s1 += sin(x);
	  });
	for (double x = 0; x < X; x += 0.1) s2 += sin(x);
	f.wait();
	timespec rt1, ct1, tt1;
	clock_gettime(CLOCK_REALTIME, &rt1);
	clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ct1);
	clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tt1);
	cout << "Real time: " << duration(rt1, rt0) << "s, "
	  "CPU time: " << duration(ct1, ct0) << "s, "
	  "Thread time: " << duration(tt1, tt0) << "s" <<
	  endl;
}
\end{lstlisting}

两个线程都在进行计算，因此程序的CPU时间是实际时间的两倍:

\begin{tcblisting}{commandshell={}}
Real time: 0.5327s, CPU time: 1.01s, Thread time: 0.5092s
\end{tcblisting}

这还不错：我们在0.53秒的实时时间内完成了1秒的计算。理想情况下，这应该是0.5秒，但在现实中，启动线程和等待线程会有一定的开销。另外，两个线程中的一个可能会花费稍长的时间来完成工作，而另一个线程在某些时候空闲。

对程序进行基准测试是一种收集性能数据的方法。通过观察执行一个函数，或处理一个事件所花费的时间，我们可以对代码的性能了解很多。在计算密集型的代码中，可以了解程序是否真的在不间断地进行计算，或者正在等待什么。对于多线程程序，可以测量并发的有效性和开销。不仅限于收集执行时间:还可以输出我们认为相关的任何计数和值:调用一个函数的次数、排序的平均字符串的长度等，以便我们进行分析程序的各项指标。

然而，这种灵活性是有代价的:使用基准测试，可以了解任何关于程序性能的问题。不过，必须先问一个问题:这里只报告了测量数据。如果想知道某个函数需要多长时间，就必须给它添加计时器。问题是，在代码中到处撒计时器是不行的:这些函数的调用代价相当昂贵，所以使用太多会减慢程序的速度，并严重影响性能测试。具有充足的经验和良好的编码规则，可以提前编写一些代码，这样可以针对其主要部分进行基准测试了。

如果你不知道从哪里开始，应该怎么做？如果接手了一个没有进行任何基准测试的代码库，该怎么办？或者，性能瓶颈隔在一大坨代码中，但其中没有更多的计时器，应该怎么办？一种方法是继续测试代码，直到有足够的数据来分析问题。不过，这种暴力的方法很慢，所以需要一些关于性能数据分析的引导。这就是\textbf{分析工具}的作用所在:它可以自动收集程序的性能数据，不是手工检测，以便进行简单的基准测试。我们将在下一节中学习如何使用性能分析工具。






