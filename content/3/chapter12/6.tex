
设计往往是妥协的艺术，有一些相互竞争的目标和要求必须得到平衡。本节中，将具体讨论与性能相关的权衡。在设计高性能系统时，需要做出许多这样的决定。以下是需要注意的问题。

\subsubsubsection{12.6.1\hspace{0.2cm}接口设计}

本章中，我们已经看到了尽可能少地公开实现的好处。但是，我们从中获得的优化自由与非常抽象的接口的成本之间存在着一种矛盾。 

这种矛盾关系需要在优化不同的组件之间进行权衡:不以任何方式限制实现的接口通常会对客户端造成相当严重的限制，例如：让我们重新回顾点的集合。在不限制其实施的情况下，我们能做什么？不允许任何插入操作，除非在末尾(实现可以是一个\texttt{vector}，复制集合的一半在性能上是不可接受的)。我们只能追加到末尾，这意味着不能保持有序，例如：不允许随机访问(集合可以存储在列表中)。如果压缩集合，甚至可能无法提供反向迭代器。给实现者留下几乎无限自由的点集合，现在只能使用前向迭代器(流访问)和追加操作。即使是后者也是一种限制，一些压缩方案要求在读取数据之前对数据进行处理，因此集合可以处于只写或只读状态。

我们给出这个示例，并不是为了演示追求与实现无关的API如何导致对客户端的限制。恰恰相反，这是处理大量数据的有效设计。集合通过添加到末尾进行写入，在写入完成之前，数据没有特定的顺序。最终可能包括排序和压缩。要读取集合，需要动态地解压缩它(如果压缩算法同时在几个点上工作，需要一个缓冲区来保存未压缩的数据)。如果集合需要编辑，可以使用我们在第4章中介绍的算法，来实现内存高效的编辑或字符串，总是从头到尾读取整个集合，并根据需要修改每个点，添加新的点等。我们将结果写入新的集合，并最终删除原来的集合。这种设计允许非常高效的数据存储，无论是在内存使用(高压缩)方面，还是在高效的内存访问方面(仅缓存友好的顺序访问)。它还要求客户端实现流访问和读-改-写的所有操作。 

You can arrive at the same point from the other end: if you analyze your data access patterns and conclude that you can live with streaming access and read-modify-write updates, you can make that part of your design. Not a specific compression scheme, of course, but the high-level data organization: writing must be finalized before anything can be read, and the only way to alter the data is to copy the entire collection to a new one, modifying its content during copying as needed. 

An interesting observation about this trade-off is that not only may we have to balance performance requirements against ease of use or other design considerations, but there is usually a decision to be made about which aspect of performance is more important. Usually, the low-level components should be given precedence: their architecture is more fundamental to the overall design than the choice of algorithms in higher-level components. Thus, it is harder to change later, which makes it more important to make an informed design decision. Note that, when it comes to designing components, there are other trade-offs to be made. 

\subsubsubsection{12.6.2\hspace{0.2cm}组件设计}

We have just seen that sometimes for one component to have a great performance by design, limitations must be imposed on other components whose performance then requires careful choice of algorithms and skillful implementation. But this is not the only trade-off we have to make. 

One of the most common balancing acts in design for performance is that of choosing the appropriate granularity level for components and modules. Making small components is generally a good design practice, particularly in test-driven design (but generally in any design that has testability as one of the goals). On the other hand, splitting the system into too many pieces with restricted interactions between them can be bad for performance. Often, treating larger units of data and code as single components allows for more efficient implementation. Again, our point collection is an example: it is more efficient if we don't allow unrestricted access to point objects inside the collection. 

In the end, these decisions should be made by considering the conflicting requirements and taking advantage of the opportunities to resolve the contradictions. It would be good to have a point as a separate unit, testable and reusable in other code. But do we really need to expose the point collection as a collection of these point units? Perhaps, we can instead treat it as a collection of all the information contained in the points it stores, while the point object is created only for reading and writing points into the collection, one at a time. This approach allows us to retain good modularity and achieve high performance. In general, the interfaces are implemented in terms of clear and testable components, while internally, the larger components store the data in an entirely different format. 

What should be avoided is creating "back doors" in the interfaces that are made specifically to work around the restrictions that resulted from following good design practices but now lead to performance limitations. This generally compromised both competing design goals in an ad hoc manner. Instead, it is better to redesign the involved components. If you don't see a way to resolve the contradicting requirements, erase the component boundary and make the smaller units into internal, implementation-specific subcomponents.

Another design aspect we have not concerned ourselves at all with so far is error handling, so a few words are in order.

\subsubsubsection{12.6.3\hspace{0.2cm}错误和未定义行为}

Error handling is one of those things that are often treated as an afterthought but should be an equal and important factor in design decisions. In particular, it is very difficult to add exception safety (and, by extension, error safety) to a program that was not designed with a particular exception-handling methodology in mind.

Error handling begins with the interfaces: all interfaces are essentially contracts that govern the interactions between components. These contracts should include any restrictions on the input data: a component will function as specified if certain external conditions are met. But the contract should also specify what happens if the conditions are not met and the component cannot fulfill the contract (or the programmer decided that it is undesirable or too difficult to do so). 

Much of this error response should also be covered by the contract: if the specified requirements are not met, the component will report an error in a certain way. It could be exceptions, error codes, status flags, or a combination of other methods. Other books are written on the best practices of error handling. Here we focus on performance.

From the performance point of view, the most important consideration is usually the overhead of handling a potential error in the much more common case when the inputs and the results are correct and nothing bad happens. It is often expressed simply as "error handling must be cheap."

What is meant by this is that error handling must be cheap in the normal, no-error case. Conversely, we usually don't care about the expense of processing errors when this rare event actually happens. What exactly this entails varies greatly from one design to the next one. 

For example, in applications that handle transactions, we usually want commit-or-rollback semantics: each transaction either succeeds or does nothing at all. The performance cost of such a design may be high, however. Often, it is acceptable to have a failed transaction still affect some changes, as long as these changes do not change the primary invariants of the system. For a disk-based database, it may be acceptable to waste some space on disk; then, we can always allocate the space for the transaction and write to the disk, but, in case of error, we leave this partially written region inaccessible to the user.

In such cases where we "hide" the full consequences of an error to improve performance, it is good to design a separate mechanism to clean such aftereffects of errors. For our database, such cleanup can proceed in a separate background process with low priority to avoid interfering with the primary accesses. Again, this is an example of resolving contradictions by separating them in time: if we have to recover from errors but it is too expensive to do so, do the expensive part later.

Finally, we have to consider the possibility that even detecting a contract violation is too expensive in some cases. Chapter 11, Undefined Behavior and Performance, covered this scenario. The interface contract should clearly state that if certain restrictions are violated, the results are undefined. If you choose this approach, do not make the program spend time making the undefined results more "acceptable." Undefined means undefined; anything can happen. This should not be done lightly, and you should consider alternatives such as lightweight data collection that leaves the expensive work to the code path that handles the real errors when they occur. But being clear about the contract boundaries and undefined outcomes is preferable to uncertain alternatives along the lines of "we will do the best we can, but no promises." 

There are many trade-offs that have to be made during the design stage, and this chapter is not meant to be a complete list of trade-offs or an all-encompassing guide to achieving balance. Instead, we show several commonly occurring contradictions and the possible approaches to resolving them. 

In order to make informed decisions when balancing performance design goals against other targets and motivations, it is important to have some performance estimates. But how do we get performance metrics so early in the design stage? This is the last and, in some ways, the hardest part of designing for performance that we are yet to discuss.














